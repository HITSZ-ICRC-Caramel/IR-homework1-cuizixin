{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jieba\n",
    "import re\n",
    "import pickle\n",
    "from utils import pre_processing, load_raw_docs\n",
    "from config import input_file, file_after_seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入语料库\n",
    "from utils import raw_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/x5/cz035yvn1lx08dx1bgv55q1w0000gn/T/jieba.cache\n",
      "Loading model cost 1.060 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "CPU times: user 2min 59s, sys: 16.1 s, total: 3min 16s\n",
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 对语料库预处理，包括：去除非中文汉字符号、分词、去除停用词\n",
    "output_f = open(file_after_seg, 'w')\n",
    "flag = 0\n",
    "for line in raw_docs:\n",
    "    output_line = pre_processing(line) + \"\\n\"\n",
    "    flag = flag + 1\n",
    "    if flag%1000==0:\n",
    "        print(flag)\n",
    "    output_f.write(output_line)\n",
    "output_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取语料库的词汇表\n",
    "seg_f = open(file_after_seg, 'r')\n",
    "lexicon = set()\n",
    "for line in seg_f.readlines():\n",
    "    for word in line.split():\n",
    "        lexicon.add(word)\n",
    "seg_f.close()\n",
    "lexicon = list(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148624"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存语料库的词汇表\n",
    "pickle.dump(lexicon,open('./cache/lexicon.k','wb'))\n",
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取各个文档的词汇表\n",
    "seg_f = open(file_after_seg, 'r')\n",
    "lexicon_doc = []\n",
    "for line in seg_f.readlines():\n",
    "    lexicon_doc.append(set(line.split()))\n",
    "seg_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30847"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存各个文档的词汇表\n",
    "pickle.dump(lexicon_doc,open('./cache/lexicon_doc.k','wb'))\n",
    "len(lexicon_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建表，word2docs，word对应包含该word的文档编号\n",
    "word2docs = dict()\n",
    "for word in lexicon:\n",
    "    word2docs[word] = set()\n",
    "for idx in range(len(lexicon_doc)):\n",
    "    for word in lexicon_doc[idx]:\n",
    "        word2docs[word].add(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存word2docs\n",
    "pickle.dump(word2docs, open('./cache/word2docs.k', 'wb'))\n",
    "len(word2docs['高盛'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
